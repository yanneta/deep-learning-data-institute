{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification with LSTM\n",
    "In this notebook we will use LSTMs to do sentiment classification on the [imdb dataset](http://ai.stanford.edu/~amaas/data/sentiment/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data: <br>\n",
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/aclImdb/README'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru-86.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-81.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-78.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru-88.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/test'),\n",
       " PosixPath('/data2/yinterian/aclImdb/model-gru-87.pth'),\n",
       " PosixPath('/data2/yinterian/aclImdb/imdbEr.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train'),\n",
       " PosixPath('/data2/yinterian/aclImdb/imdb.vocab')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"/data2/yinterian/aclImdb/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "path.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time run this\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x.lower())\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', '.', 'it', 'ran', 'at']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "spacy_tok(path.read_text())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/data2/yinterian/aclImdb/train/pos/8030_9.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/8819_10.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/6316_8.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/4781_8.txt'),\n",
       " PosixPath('/data2/yinterian/aclImdb/train/pos/10085_10.txt')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
    "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
    "all_files = pos_files + neg_files\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for path in all_files:\n",
    "    counts.update(spacy_tok(path.read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87130"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(counts):\n",
    "    if counts[word] < 5:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29370"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"<PAD>\":0, \"UNK\":1}\n",
    "words = [\"<PAD>\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you could imprive this function by taking a random sample\n",
    "# when sentences are longer than N=400 words \n",
    "def encode_sentence_v1(path, vocab2index, N=400):\n",
    "    x = spacy_tok(path.read_text())\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    enc[N-l:] = enc1[:l]\n",
    "    return enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "         929,   732,    99,  2115,    99,   231,    23,  2888,    28,\n",
       "         428,   788,   119,    52,   890,   127,  1885,   264,  1489,\n",
       "         987,    93,   390,  4499,    93,  4500,    75,  2203,  1047,\n",
       "          75, 18225,    47,   483,   141,  1574,    23,  2994,    34,\n",
       "          26, 16331,   353,   705,   881,    73,   141,   197,  2624,\n",
       "        3058,    52,     3,   184,  4303,    52, 10076,    30,   117,\n",
       "          12,   264,    98,    26,  1498,  1132,     2,     8,    66,\n",
       "        6401,  2205,    47,   353,    58,    23,  2115,   353,  7441,\n",
       "       24959,    73,   666,   751,  1362,   141,   287,     2,  1885,\n",
       "         967,    47,   696,    73,    52,  1074,   801,  5503,    47,\n",
       "        1966,    73,    26,    62,    71,    52,    68,  4209,     3,\n",
       "       16734,    73,    42,   490, 18225,    63, 13088,  7768,    47,\n",
       "           2,    66,  2606,  4048,    58,     5,    73,  5561,   167,\n",
       "         536,    42,   105,     1,   615,  4459,    71,    66,   161,\n",
       "         178,   141,  2163,    86,    73,   324,  1280,    99,     5,\n",
       "          99,  1885,  3756,   285,    26,   779,   105, 12384,   184,\n",
       "          83,   265,  2823,    23,  1180,  2413,   790,    34,   415,\n",
       "        3350,  1012,    73,  9284,  1235,    73,   184,   666,   751,\n",
       "        1362,   141,   287,    23,  2888,    28,  2707, 24658,  4594,\n",
       "          47,  2183,    73,    89,    52,   266, 14782,    70,    71,\n",
       "          90,    26,  1498,     3,   112,    10,    52,   981,   161,\n",
       "        1584,  4499,  4500,    73,    26,  3007,   219,   353,    34,\n",
       "         196,   353,  1738,    47,    83,   219,  7063,    30,    83,\n",
       "         751,  1223,   765,    30,    15,    43,   141,    26,  1720,\n",
       "          71,    52,     3,   335,    93, 27500,   227,    26,   132,\n",
       "        6802,  1498,  4514,    73,   119,   276,   257,    26,  1498,\n",
       "          47,    54, 21362,    23,  5595,  5422,     8,   353,  1306,\n",
       "         127,   193,    13,    23,  1431,  3942,  4514,   353,    26,\n",
       "       13088,  2413,  3534,    75,    23,  1345,   114,  2180,   424,\n",
       "          47,    26,  9757, 16331,  1939,    73,    90,    54,    98,\n",
       "        4499,  4500,   506,   105,   552,     8,    73,    10,    15,\n",
       "          54,   751,   384,   239,   112,  2115,   919,    25,   353,\n",
       "         785,    15,    73,   324,   151,    84,     2,   608,    23,\n",
       "        9986,  2117,   536,   193,   105,   415,  1203,  2037,    28,\n",
       "       11090,    25,     2,    73], dtype=int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "encode_sentence(path, vocab2index, N=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDatasetv1(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\", N=400):\n",
    "        self.N = N\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        return encode_sentence(path, vocab2index, self.N), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_v1 = ImdbDatasetv1(PATH)\n",
    "test_ds_v1 = ImdbDatasetv1(PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl_v1 = DataLoader(train_ds_v1, batch_size=batch_size, shuffle=True)\n",
    "test_dl_v1 = DataLoader(test_ds_v1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LSTMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
    "# Output dim is the dimension of the hidden layer (4 in this example)\n",
    "# batch_first â€“ If True, then the input and output tensors are provided as (batch, seq, feature).\n",
    "lstm = nn.LSTM(2, 4, batch_first=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.5123, -1.8904],\n",
       "         [ 1.6441, -0.8196],\n",
       "         [ 0.4953,  0.8664],\n",
       "         [ 0.2091, -0.7583],\n",
       "         [ 0.8346, -0.0706]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 2) for _ in range(5)] # make a sequence of length 5\n",
    "inputs = torch.cat(inputs).view( 1, len(inputs),  -1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNNs assume this input shape\n",
    "# input shape should be  bash_size x seq_len x embedding dimension (if batch_first=True)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0340,  0.1957,  0.1785, -0.2185],\n",
       "         [-0.1098,  0.2564,  0.1409, -0.3286],\n",
       "         [-0.3621,  0.0015, -0.0616, -0.2750],\n",
       "         [-0.2830,  0.0663,  0.1183, -0.2650],\n",
       "         [-0.3131,  0.0708,  0.0988, -0.2679]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.3131,  0.0708,  0.0988, -0.2679]]], grad_fn=<ViewBackward>),\n",
       " tensor([[[-0.6365,  0.1603,  0.1475, -0.5192]]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModelv1(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModelv1,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs) :\n",
    "        x = self.embeddings(inputs)\n",
    "        lstm_out, lstm_h = self.lstm(x)\n",
    "        x = lstm_out[:,-1]\n",
    "        x = self.linearOut(x)\n",
    "        return x, lstm_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds_v1, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_dl))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400, 10])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embed(x.long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 9\n",
    "lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "out, hidden = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400, 9])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 9])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a vector of size 9 (hidden_dim) for every element on the batch\n",
    "out[:,-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, train_dl, test_dl, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y in train_dl:\n",
    "            x = x.long().cuda()\n",
    "            y = y.float().cuda()\n",
    "            y_pred, _ = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        print(\"train loss %.3f\" % (sum_loss/total))\n",
    "        test_metrics(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(model, test_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, y in test_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.float().cuda().unsqueeze(1)\n",
    "        y_hat, _ = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    print(\"test loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29372\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMModelv1(vocab_size, 50, 100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl_v1 = DataLoader(train_ds_v1, batch_size=batch_size, shuffle=True)\n",
    "test_dl_v1 = DataLoader(test_ds_v1, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.680\n",
      "test loss 0.673 and accuracy 0.568\n",
      "train loss 0.598\n",
      "test loss 0.569 and accuracy 0.704\n",
      "train loss 0.449\n",
      "test loss 0.458 and accuracy 0.798\n",
      "train loss 0.330\n",
      "test loss 0.515 and accuracy 0.741\n",
      "train loss 0.370\n",
      "test loss 0.486 and accuracy 0.784\n",
      "train loss 0.261\n",
      "test loss 0.505 and accuracy 0.806\n",
      "train loss 0.180\n",
      "test loss 0.474 and accuracy 0.818\n",
      "train loss 0.130\n",
      "test loss 0.501 and accuracy 0.825\n",
      "train loss 0.089\n",
      "test loss 0.544 and accuracy 0.830\n",
      "train loss 0.073\n",
      "test loss 0.627 and accuracy 0.823\n",
      "train loss 0.048\n",
      "test loss 0.635 and accuracy 0.830\n",
      "train loss 0.030\n",
      "test loss 0.703 and accuracy 0.819\n",
      "train loss 0.026\n",
      "test loss 0.750 and accuracy 0.825\n",
      "train loss 0.016\n",
      "test loss 0.863 and accuracy 0.835\n",
      "train loss 0.010\n",
      "test loss 0.873 and accuracy 0.830\n",
      "train loss 0.008\n",
      "test loss 0.958 and accuracy 0.825\n",
      "train loss 0.007\n",
      "test loss 0.962 and accuracy 0.833\n",
      "train loss 0.013\n",
      "test loss 0.940 and accuracy 0.823\n",
      "train loss 0.015\n",
      "test loss 0.920 and accuracy 0.831\n",
      "train loss 0.008\n",
      "test loss 0.977 and accuracy 0.828\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, train_dl_v1, test_dl_v1, epochs=20, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-82.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2 GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs) :\n",
    "        x = self.embeddings(inputs)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, lstm_h = self.gru(x)\n",
    "        x = lstm_out[:, -1]\n",
    "        x = self.linearOut(x)\n",
    "        return x, lstm_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29372\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model2 = GRUModel(vocab_size, 50, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.665\n",
      "test loss 0.606 and accuracy 0.677\n",
      "train loss 0.632\n",
      "test loss 0.773 and accuracy 0.624\n",
      "train loss 0.510\n",
      "test loss 0.545 and accuracy 0.752\n",
      "train loss 0.404\n",
      "test loss 0.413 and accuracy 0.824\n",
      "train loss 0.339\n",
      "test loss 0.422 and accuracy 0.834\n",
      "train loss 0.253\n",
      "test loss 0.344 and accuracy 0.870\n",
      "train loss 0.195\n",
      "test loss 0.321 and accuracy 0.877\n",
      "train loss 0.161\n",
      "test loss 0.341 and accuracy 0.880\n",
      "train loss 0.126\n",
      "test loss 0.385 and accuracy 0.879\n",
      "train loss 0.103\n",
      "test loss 0.422 and accuracy 0.874\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model2, train_dl_v1, test_dl_v1, epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-82.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function encodes sentences without padding \n",
    "def encode_sentence_v2(path, vocab2index):\n",
    "    x = spacy_tok(path.read_text().lower())\n",
    "    return np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  929,   732,    99,  2115,    99,   231,    23,  2888,    28,\n",
       "         428,   788,   119,    52,   890,   127,  1885,   264,  1489,\n",
       "         987,    93,   390,  4499,    93,  4500,    75,  2203,  1047,\n",
       "          75, 18225,    47,   483,   141,  1574,    23,  2994,    34,\n",
       "          26, 16331,   353,   705,   881,    73,   141,   197,  2624,\n",
       "        3058,    52,     3,   184,  4303,    52, 10076,    30,   117,\n",
       "          12,   264,    98,    26,  1498,  1132,     2,     8,    66,\n",
       "        6401,  2205,    47,   353,    58,    23,  2115,   353,  7441,\n",
       "       24959,    73,   666,   751,  1362,   141,   287,     2,  1885,\n",
       "         967,    47,   696,    73,    52,  1074,   801,  5503,    47,\n",
       "        1966,    73,    26,    62,    71,    52,    68,  4209,     3,\n",
       "       16734,    73,    42,   490, 18225,    63, 13088,  7768,    47,\n",
       "           2,    66,  2606,  4048,    58,     5,    73,  5561,   167,\n",
       "         536,    42,   105,     1,   615,  4459,    71,    66,   161,\n",
       "         178,   141,  2163,    86,    73,   324,  1280,    99,     5,\n",
       "          99,  1885,  3756,   285,    26,   779,   105, 12384,   184,\n",
       "          83,   265,  2823,    23,  1180,  2413,   790,    34,   415,\n",
       "        3350,  1012,    73,  9284,  1235,    73,   184,   666,   751,\n",
       "        1362,   141,   287,    23,  2888,    28,  2707, 24658,  4594,\n",
       "          47,  2183,    73,    89,    52,   266, 14782,    70,    71,\n",
       "          90,    26,  1498,     3,   112,    10,    52,   981,   161,\n",
       "        1584,  4499,  4500,    73,    26,  3007,   219,   353,    34,\n",
       "         196,   353,  1738,    47,    83,   219,  7063,    30,    83,\n",
       "         751,  1223,   765,    30,    15,    43,   141,    26,  1720,\n",
       "          71,    52,     3,   335,    93, 27500,   227,    26,   132,\n",
       "        6802,  1498,  4514,    73,   119,   276,   257,    26,  1498,\n",
       "          47,    54, 21362,    23,  5595,  5422,     8,   353,  1306,\n",
       "         127,   193,    13,    23,  1431,  3942,  4514,   353,    26,\n",
       "       13088,  2413,  3534,    75,    23,  1345,   114,  2180,   424,\n",
       "          47,    26,  9757, 16331,  1939,    73,    90,    54,    98,\n",
       "        4499,  4500,   506,   105,   552,     8,    73,    10,    15,\n",
       "          54,   751,   384,   239,   112,  2115,   919,    25,   353,\n",
       "         785,    15,    73,   324,   151,    84,     2,   608,    23,\n",
       "        9986,  2117,   536,   193,   105,   415,  1203,  2037,    28,\n",
       "       11090,    25,     2,    73])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "encode_sentence(path, vocab2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDatasetv2(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\"):\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        path = self.files[idx]\n",
    "        return encode_sentence(path, vocab2index), self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_v2 = ImdbDatasetv2(PATH)\n",
    "test_ds_v2 = ImdbDatasetv2(PATH, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "779"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = test_ds_v2[0]\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = train_ds_v2[0]\n",
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## collate_fn function\n",
    "\n",
    "The `collate_fn` merges a list of samples to form a mini-batch. It is an optional parameter to our data loader. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 545, 23, 1], [34, 84], [23, 6, 774]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [([4, 545, 23, 1], 0), ([34, 84], 1), ([23, 6, 774], 0)]\n",
    "sentences, labels = zip(*data)\n",
    "list(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"Creates mini-batch tensors from the list of tuples (sentences, labels).\n",
    "    \n",
    "    Need custom collate_fn because merging sequences (including padding) is not \n",
    "    supported in default. Sequences are padded to the maximum length of mini-batch \n",
    "    sequences (dynamic padding).\n",
    "    \n",
    "    Args:\n",
    "        data: list of tuple (sentence, label). \n",
    "            - list of word indices of variable length\n",
    "            - label, 0 or 1\n",
    "    Returns:\n",
    "        packed_batch: (PackedSequence), see torch.nn.utils.rnn.pack_padded_sequence\n",
    "        sencences: torch tensor of shape (batch_size, max_len).\n",
    "        labels: torch tensor of shape (batch_size, 1).\n",
    "        lengths: list; valid length for each padded sentence. \n",
    "    \"\"\"\n",
    "    # Sort a data list by sentences length (descending order).\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, labels = zip(*data)\n",
    "    \n",
    "    # stack labels\n",
    "    labels = torch.Tensor(labels).unsqueeze(1)\n",
    "    \n",
    "    # Merge sentences\n",
    "    lengths = [len(s) for s in sentences]\n",
    "   \n",
    "    sents = torch.zeros(len(sentences), max(lengths)).long()\n",
    "    for i, s in enumerate(sentences):\n",
    "        end = lengths[i]\n",
    "        sents[i, :end] = torch.Tensor(s[:end])        \n",
    "    \n",
    "    return sents, labels, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_dl_v2 = DataLoader(train_ds_v2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dl_v2 = DataLoader(test_ds_v2, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, labels, lengths = next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 606]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[606, 209, 181, 169, 152]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        x = self.embeddings(inputs)\n",
    "        pack = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        lstm_out, (ht, ct) = self.lstm(pack)\n",
    "        x = ht[-1]\n",
    "        x = self.linearOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "train_dl_v2 = DataLoader(train_ds_v2, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "test_dl_v2 = DataLoader(test_ds_v2, batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29372\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMModel(vocab_size, 50, 100).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.651\n",
      "test loss 0.558 and accuracy 0.718\n",
      "train loss 0.548\n",
      "test loss 0.529 and accuracy 0.749\n",
      "train loss 0.392\n",
      "test loss 0.396 and accuracy 0.831\n",
      "train loss 0.275\n",
      "test loss 0.505 and accuracy 0.768\n",
      "train loss 0.255\n",
      "test loss 0.397 and accuracy 0.857\n"
     ]
    }
   ],
   "source": [
    "model = train_epocs(model, train_dl_v2, test_dl_v2, epochs=5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-85.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss 0.939 and accuracy 0.817\n"
     ]
    }
   ],
   "source": [
    "test_metrics(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linearOut = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, inputs, lengths):\n",
    "        x = self.embeddings(inputs)\n",
    "        pack = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        out, ht = self.gru(pack)\n",
    "        x = ht[-1]\n",
    "        x = self.dropout(x)\n",
    "        x = self.linearOut(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29372\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model2 = GRUModel(vocab_size, 50, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.648\n",
      "test loss 0.623 and accuracy 0.663\n",
      "train loss 0.512\n",
      "test loss 0.377 and accuracy 0.841\n",
      "train loss 0.261\n",
      "test loss 0.270 and accuracy 0.889\n",
      "train loss 0.144\n",
      "test loss 0.306 and accuracy 0.887\n",
      "train loss 0.074\n",
      "test loss 0.377 and accuracy 0.882\n"
     ]
    }
   ],
   "source": [
    "model2 = train_epocs(model2, epochs=5, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"model-gru-88.pth\"\n",
    "save_model(model2, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Start with pre-trained embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this notebook is adapted from this [pytorch tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html). \n",
    "\n",
    "The data loader function `collate_fn` has been adapted from [here](https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/image_captioning/data_loader.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
