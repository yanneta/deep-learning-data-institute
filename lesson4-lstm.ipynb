{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment classification with LSTM\n",
    "In this notebook we will use LSTMs to do sentiment classification on the [imdb dataset](http://ai.stanford.edu/~amaas/data/sentiment/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from spacy.symbols import ORTH\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data: <br>\n",
    "`wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_dataset():\n",
    "    ! mkdir -p data/aclImdb\n",
    "    ! wget http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "    ! tar -zxvf aclImdb_v1.tar.gz -C data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unpack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/aclImdb/imdbEr.txt'),\n",
       " PosixPath('data/aclImdb/test'),\n",
       " PosixPath('data/aclImdb/imdb.vocab'),\n",
       " PosixPath('data/aclImdb/README'),\n",
       " PosixPath('data/aclImdb/train')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "PATH = Path(\"data/aclImdb/\")\n",
    "list(PATH.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High\\'s satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers\\' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I\\'m here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn\\'t!'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "path.read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first time run this\n",
    "#!python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
    "\n",
    "my_tok = spacy.load('en')\n",
    "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bromwell', 'High', 'is', 'a', 'cartoon', 'comedy', '.', 'It', 'ran', 'at']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/pos/0_9.txt\"\n",
    "spacy_tok(path.read_text())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing vocab2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/aclImdb/train/pos/4715_9.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/12390_8.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/8329_7.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/9063_8.txt'),\n",
       " PosixPath('data/aclImdb/train/pos/3092_10.txt')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_files = list((PATH/\"train\"/\"pos\").iterdir())\n",
    "neg_files = list((PATH/\"train\"/\"neg\").iterdir())\n",
    "all_files = pos_files + neg_files\n",
    "all_files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for path in all_files:\n",
    "    counts.update(spacy_tok(path.read_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33914"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in list(counts):\n",
    "    if counts[word] < 5:\n",
    "        del counts[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33914"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "words = [\"\", \"UNK\"]\n",
    "for word in counts:\n",
    "    vocab2index[word] = len(words)\n",
    "    words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that spacy_tok takes a while run it just once\n",
    "def encode_sentence(path, vocab2index, N=400, padding_start=True):\n",
    "    x = spacy_tok(path.read_text())\n",
    "    enc = np.zeros(N, dtype=np.int32)\n",
    "    enc1 = np.array([vocab2index.get(w, vocab2index[\"UNK\"]) for w in x])\n",
    "    l = min(N, len(enc1))\n",
    "    if padding_start:\n",
    "        enc[:l] = enc1[:l]\n",
    "    else:\n",
    "        enc[N-l:] = enc1[:l]\n",
    "    return enc, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            1,  6069,    40,  3675,    40,   391,     3,  3812,    13,\n",
       "         1828,  3517,    58,   185,   822,    63,   205,    69,   525,\n",
       "          731,   132,  2250, 16153,   132,  9762,    84,   497,  4027,\n",
       "           84, 26204,   115,  2101,    71,  2066,     3,     1,   252,\n",
       "           77, 14433,  1544,   409,   524,    20,   222,   363,  1634,\n",
       "         1507,   185,   167,   456,  4553,   185,  1643,    28,   460,\n",
       "          508,    69,   576,    77,    86,  5130,    18,     4,    25,\n",
       "         3790,   444,   115,  1544,    44,     3,  3675,  1544,  5313,\n",
       "        31875,    20,  1294,   269,  4429,    71,  1762,    18,   205,\n",
       "         3750,   115,  2201,    20,   185,  1138,   301, 13181,   115,\n",
       "         2370,    20,    33,   633,     5,   185,  8120,  3795,   167,\n",
       "        13997,    20,   262,   862, 26204,   102,  6019,  6998,   115,\n",
       "           18,    25,   417,   216,    44,   126,    20, 23462,   176,\n",
       "          537,   262,    61,     1,  6296,  2690,     5,    25,   425,\n",
       "          282,    71,  1859,    50,    20,  1362,   596,    40,   126,\n",
       "           40,   205, 16476,    94,    77,  2472,    61, 16822,   456,\n",
       "          190,   306,  6087,     3,  1133,  3482,  1777,   252,    35,\n",
       "         4199,  4815,    20, 27751,  2307,    20,   462,  1421,   269,\n",
       "         4429,    71,  1762,     3,  3812,    13,  4427, 12325,  5868,\n",
       "          115,   127,    20,   215,   185,   543,  5906,   297,     5,\n",
       "          162,    77,    86,   167,   493,    53,   185,  1255,   425,\n",
       "         1347, 16153,  9762,    20,    33,  4837,   387,  1544,   252,\n",
       "          138,  1544,  8433,   115,   190,   387,  6699,    28,  1470,\n",
       "          269, 16596,   184,    28,   194,  1436,    71,    77,   728,\n",
       "            5,   185,   167,  1761,   132, 31613,   973,    77,   948,\n",
       "         3804,    86,  2849,    20,    58,  3446,   178,    77,    86,\n",
       "          115,   268,     1,     3,  1714,  4123,     4,  1544,  1415,\n",
       "           63,   469,    11,     3,  2188,  3998,  2849,  1544,    77,\n",
       "         6019,  3482,  3461,    84,     3,  1213,    27,  8554,  1746,\n",
       "          115,    77, 11112, 14433,   440,    20,   328,   268,   576,\n",
       "        16153,  9762,  1316,    61,   521,     4,    20,   272,   271,\n",
       "          268,   269,  1064,    17,   493,  3675,  1303,   199,  1544,\n",
       "         1542,   271,    20,  1362, 14576,  1042,    18,  1037,     3,\n",
       "        11670,  2971,   537,   469,    61,    35,   455,   932,    13,\n",
       "          294,   199,    18,    20], dtype=int32), 310)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = PATH/\"train/neg/211_4.txt\"\n",
    "encode_sentence(path, vocab2index, N=400, padding_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImdbDataset(Dataset):\n",
    "    def __init__(self, PATH, train=\"train\", N=400, padding_start=True):\n",
    "        self.path_to_images = PATH/train\n",
    "        self.pos_files = list((self.path_to_images/\"pos\").iterdir())\n",
    "        self.neg_files = list((self.path_to_images/\"neg\").iterdir())\n",
    "        self.files = self.pos_files + self.neg_files\n",
    "        # pos 1, neg 0\n",
    "        self.y = np.concatenate((np.ones(len(self.pos_files), dtype=int),\n",
    "                                np.zeros(len(self.neg_files), dtype=int)), axis=0)\n",
    "        # it is important to run encode_sentence in the init\n",
    "        self.X = [encode_sentence(path, vocab2index, N, padding_start) for path in self.files]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x, s = self.X[idx]\n",
    "        return x, s, self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_v0 = ImdbDataset(PATH, padding_start=False)\n",
    "valid_ds_v0 = ImdbDataset(PATH, \"test\", padding_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "train_dl_v0 = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
    "valid_dl_v0 = DataLoader(valid_ds_v0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         47,  48,   4,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,\n",
       "         59,  13,  60,  61,  40,   1,  62,  40,  63,  44,   3,  64,  53,\n",
       "         65,  66,  67,  50,   3,   1,  68,  69,  25,  70,  71,  72,  17,\n",
       "         73,  74,  75,  55,  76,  77,   1,  71,  78,  28,  33,  79,  50,\n",
       "         57,  80,  11,  81,  82,  83,  84,  77,  85,  86,  25,  87,  84,\n",
       "         88,  89,  25,  90,  44,  56,  61,  91,  84,  53,  92,  57,  93,\n",
       "         94,   3,  95,  96,  97,  98,  58,  99,  55,   3, 100, 101, 102,\n",
       "         77, 103, 104,  63,  84, 105, 106, 107, 108,  20,  33, 109,  84,\n",
       "        110,   3, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121,\n",
       "        122,  84,  11,   3, 123,  12,  84, 115, 124, 125,  25, 126, 127,\n",
       "         44,   3, 128,  45, 129,  20,  33,   4,  25, 130,   3, 131, 132,\n",
       "          1,  13,  40, 133,  61, 134,  40, 115,  40,  33,   1, 135,   3,\n",
       "        136,  28, 137, 102,  77, 138, 132, 139,  55, 140, 141,  84,  40,\n",
       "         33, 142,  40,  25, 143, 144,  84, 145,  13, 146, 147, 148,  82,\n",
       "         55, 149, 150, 151,  84,  69, 152,   3, 153, 154, 155,  50, 156,\n",
       "         20, 157, 157, 157, 158, 159, 157, 157, 157, 157], dtype=int32),\n",
       " 205,\n",
       " 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_v0[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding LSTMs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input dim is the dimension of the embedding for each word (2 in the example)\n",
    "# Output dim is the dimension of the hidden layer (4 in this example)\n",
    "# batch_first â€“ If True, then the input and output tensors are provided as (batch, seq, feature). \n",
    "lstm = nn.LSTM(2, 4, batch_first=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5128,  1.4743],\n",
       "         [-1.4117, -1.0552],\n",
       "         [-2.1035,  0.2079],\n",
       "         [-0.0191, -1.2118],\n",
       "         [-0.2157,  1.2554]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [torch.randn(1, 2) for _ in range(5)] # make a sequence of length 5\n",
    "inputs = torch.cat(inputs).view(1, len(inputs), -1)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 2])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNNs with batch_first=True assume this input shape\n",
    "# input shape should be bash_size x seq_len x embedding dimension\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, (hidden, cell) = lstm(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0362,  0.3095, -0.2179,  0.0650],\n",
       "         [ 0.1125, -0.0461, -0.3170, -0.0404],\n",
       "         [ 0.0267, -0.0979, -0.3857, -0.0164],\n",
       "         [ 0.1729, -0.0888, -0.2652, -0.0342],\n",
       "         [ 0.0649,  0.2441, -0.3059,  0.0615]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0649,  0.2441, -0.3059,  0.0615]]], grad_fn=<StackBackward>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM V0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMV0Model(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMV0Model,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        out_pack, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs_v0(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            # s is not used in this model\n",
    "            x = x.long() #.cuda()\n",
    "            y = y.float() #.cuda()\n",
    "            y_pred = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics_v0(model, val_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics_v0(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        # s is not used here\n",
    "        x = x.long() #.cuda()\n",
    "        y = y.float().unsqueeze(1) #.cuda()\n",
    "        y_hat = model(x)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5000\n",
    "train_dl = DataLoader(train_ds_v0, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds_v0, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33916\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model_v0 = LSTMV0Model(vocab_size, 50, 50) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.688 val loss 0.683 and val accuracy 0.542\n",
      "train loss 0.637 val loss 0.629 and val accuracy 0.640\n",
      "train loss 0.542 val loss 0.561 and val accuracy 0.735\n",
      "train loss 0.428 val loss 0.511 and val accuracy 0.783\n",
      "train loss 0.370 val loss 0.619 and val accuracy 0.751\n",
      "train loss 0.310 val loss 0.507 and val accuracy 0.820\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model_v0, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.255 val loss 0.544 and val accuracy 0.827\n",
      "train loss 0.243 val loss 0.554 and val accuracy 0.827\n",
      "train loss 0.241 val loss 0.551 and val accuracy 0.830\n",
      "train loss 0.233 val loss 0.550 and val accuracy 0.833\n",
      "train loss 0.228 val loss 0.582 and val accuracy 0.830\n",
      "train loss 0.219 val loss 0.572 and val accuracy 0.834\n"
     ]
    }
   ],
   "source": [
    "train_epocs_v0(model_v0, epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM model with variable length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with padding at the end\n",
    "train_ds = ImdbDataset(PATH)\n",
    "valid_ds = ImdbDataset(PATH, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debugging our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x,s,y = next(iter(train_dl)) # here s is the length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 400]), torch.Size([7]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([176,  96, 204, 232, 149, 166, 175])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by length so we can use pack_padded_sequence\n",
    "s, index = s.sort(0, descending=True)\n",
    "x = x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([232, 204, 176, 175, 166, 149,  96])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 0, 6, 5, 4, 1])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 400, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = embed(x.long())\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 9\n",
    "lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN will not perform calculation on pad elements if pack_padded_sequence is used\n",
    "x_pack = pack_padded_sequence(x, list(s), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pack, (ht, ct) = lstm(x_pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 9])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## final hidden layer\n",
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 9])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2167],\n",
       "        [0.2753],\n",
       "        [0.2194],\n",
       "        [0.1846],\n",
       "        [0.1855],\n",
       "        [0.1711],\n",
       "        [0.1631]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(hidden_dim, 1)\n",
    "y_hat = linear(ht[-1])\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 1])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes back to the original ordering\n",
    "h = torch.zeros_like(y_hat).scatter_(0, index.unsqueeze(1), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2194],\n",
       "        [0.1631],\n",
       "        [0.2753],\n",
       "        [0.2167],\n",
       "        [0.1711],\n",
       "        [0.1855],\n",
       "        [0.1846]], grad_fn=<ScatterBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2167],\n",
       "        [0.2753],\n",
       "        [0.2194],\n",
       "        [0.1846],\n",
       "        [0.1855],\n",
       "        [0.1711],\n",
       "        [0.1631]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 0, 6, 5, 4, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        # sorting\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1), out) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epocs(model, epochs=10, lr=0.001):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, s, y in train_dl:\n",
    "            x = x.long() #.cuda()\n",
    "            y = y.float() #.cuda()\n",
    "            y_pred = model(x, s)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
    "        if i % 5 == 1:\n",
    "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_metrics(model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    for x, s, y in valid_dl:\n",
    "        x = x.long()  #.cuda()\n",
    "        y = y.float().unsqueeze(1) #.cuda()\n",
    "        y_hat = model(x, s)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
    "        y_pred = y_hat > 0\n",
    "        correct += (y_pred.float() == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "    return sum_loss/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model = LSTMModel(vocab_size, 50, 50) #.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.681 val loss 0.664 and val accuracy 0.593\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epocs(model, epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.222 val loss 0.611 and val accuracy 0.814\n",
      "train loss 0.204 val loss 0.677 and val accuracy 0.810\n",
      "train loss 0.207 val loss 0.666 and val accuracy 0.812\n",
      "train loss 0.197 val loss 0.625 and val accuracy 0.822\n",
      "train loss 0.190 val loss 0.695 and val accuracy 0.813\n",
      "train loss 0.188 val loss 0.696 and val accuracy 0.815\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model, epochs=30, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(m, p): torch.save(m.state_dict(), p)\n",
    "    \n",
    "def load_model(m, p): m.load_state_dict(torch.load(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"models/model-81.pth\"\n",
    "save_model(model, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6520548796653748, tensor(0.8236, device='cuda:0'))"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_metrics(model, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        x_pack = pack_padded_sequence(x, list(s), batch_first=True)\n",
    "        out_pack, ht= self.gru(x_pack)\n",
    "        out = self.linear(ht[-1])\n",
    "        return torch.zeros_like(out).scatter_(0, sort_index.unsqueeze(1).cuda(), out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33920\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(words)\n",
    "print(vocab_size)\n",
    "model2 = GRUModel(vocab_size, 50, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.687 val loss 0.682 and val accuracy 0.554\n",
      "train loss 0.582 val loss 0.610 and val accuracy 0.712\n",
      "train loss 0.404 val loss 0.590 and val accuracy 0.762\n",
      "train loss 0.279 val loss 0.416 and val accuracy 0.852\n",
      "train loss 0.182 val loss 0.491 and val accuracy 0.861\n",
      "train loss 0.141 val loss 0.496 and val accuracy 0.869\n"
     ]
    }
   ],
   "source": [
    "train_epocs(model2, epochs=30, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = PATH/\"models/model-gru-87.pth\"\n",
    "save_model(model2, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional and multiple layers GRUs / LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 7\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x,s,y = next(iter(train_dl)) # here s is the length of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 10\n",
    "hidden_dim = 9\n",
    "embed = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "lstm1 = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "lstm2 = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, index = s.sort(0, descending=True)\n",
    "x = x[index]\n",
    "x = embed(x.long())\n",
    "x_pack = pack_padded_sequence(x, list(s), batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, (ht, ct) = lstm1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 9])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 9])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht[-2,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_out, (ht2, ct2) = lstm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 7, 9])"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 9]), torch.Size([7, 9]))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht2[-2,:,:].shape, ht2[-1,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 18])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat the final forward (ht[-2,:,:]) and backward (ht[-1,:,:]) hidden layers      \n",
    "h = torch.cat((ht2[-2,:,:], ht2[-1,:,:]), dim = 1)\n",
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBiModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(LSTMBiModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        s, sort_index = torch.sort(s, 0,descending=True)\n",
    "        s = s.numpy().tolist()\n",
    "        x = x[sort_index]\n",
    "        x = self.embeddings(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
    "        out_pack, (ht, ct) = self.lstm(x_pack)\n",
    "        h = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
    "        h = self.linear(h)\n",
    "        return torch.zeros_like(h).scatter_(0, sort_index.unsqueeze(1).cuda(), h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "model3 = LSTMBiModel(vocab_size, 50, 50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epocs(model3, epochs=15, lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi GRUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUBiModel(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n",
    "        super(GRUBiModel,self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True,\n",
    "                            dropout=0.3, bidirectional=True)\n",
    "        self.linear = nn.Linear(2*hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x, s):\n",
    "        x = self.embeddings(x)\n",
    "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
    "        out_pack, ht = self.gru(x_pack)\n",
    "        h = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
    "        return self.linear(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Start with pre-trained embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this notebook is adapted from this [pytorch tutorial](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
